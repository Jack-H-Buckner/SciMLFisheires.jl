<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Building a model · SciMLFisheries.jl</title><meta name="title" content="Building a model · SciMLFisheries.jl"/><meta property="og:title" content="Building a model · SciMLFisheries.jl"/><meta property="twitter:title" content="Building a model · SciMLFisheries.jl"/><meta name="description" content="Documentation for SciMLFisheries.jl."/><meta property="og:description" content="Documentation for SciMLFisheries.jl."/><meta property="twitter:description" content="Documentation for SciMLFisheries.jl."/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">SciMLFisheries.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">SciMlFisheries</a></li><li class="is-active"><a class="tocitem" href>Building a model</a><ul class="internal"><li><a class="tocitem" href="#Production-models"><span>Production models</span></a></li><li><a class="tocitem" href="#Observation-models"><span>Observation models</span></a></li><li><a class="tocitem" href="#Uncertianty-quantification"><span>Uncertianty quantification</span></a></li></ul></li><li><a class="tocitem" href="../Modeltesting/">Testing model performance</a></li><li><a class="tocitem" href="../ModelEvaluation/">Using the fitted model</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Building a model</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Building a model</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/Jack-H-Buckner/SciMLFisheries.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/Jack-H-Buckner/SciMLFisheries.jl/blob/main/docs/src/ModelBuilders.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Building-a-model"><a class="docs-heading-anchor" href="#Building-a-model">Building a model</a><a id="Building-a-model-1"></a><a class="docs-heading-anchor-permalink" href="#Building-a-model" title="Permalink"></a></h1><p>SciMLFisheries has one primary function for building a fisheries assessment model, <code>SurplusProduction.</code> This function only requires a data set to build a model but offers several keyword arguments to allow users to modify the model structure, incorperate prior information, and optimize model performance. The function of these arguments depends on the model type and is discussed in detail below.</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="SciMLFisheries.SurplusProduction-Tuple{Any}" href="#SciMLFisheries.SurplusProduction-Tuple{Any}"><code>SciMLFisheries.SurplusProduction</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">SurplusProduction(data;kwargs ...)</code></pre><p>Initailizes a surplus production model to fit to the data set with a colum for time, harvest and the abundnace index. </p><p>table 1: example data set </p><table><tr><th style="text-align: right">t</th><th style="text-align: right">y</th><th style="text-align: right">H</th></tr><tr><td style="text-align: right">0</td><td style="text-align: right">1.0</td><td style="text-align: right">0.1</td></tr><tr><td style="text-align: right">1</td><td style="text-align: right">0.95</td><td style="text-align: right">0.15</td></tr><tr><td style="text-align: right">2</td><td style="text-align: right">0.925</td><td style="text-align: right">0.125</td></tr><tr><td style="text-align: right">...</td><td style="text-align: right">...</td><td style="text-align: right">...</td></tr></table><p>A number of key work arguments are used to modify the models behavior. Each of the key words specifies a specific model sturcture or model behavior, see the section on model types for details. </p><pre><code class="language-julia hljs">SurplusProduction(data;
        production_model = &quot;DelayEmbedding&quot;, # options = [&quot;FeedForward&quot;,&quot;LSTM&quot;,&quot;DelayEmbeddingARD&quot;,&quot;DelayEmbeddingDropOut&quot;,&quot;LSTMDropOut&quot;]
        harvest_model = &quot;DiscreteAprox&quot;, # options = [&quot;FeedForward&quot;]
        index_model = &quot;Linear&quot;, # index_model = [&quot;Nonlinear&quot;]
        regularizaiton_type = &quot;L2&quot;, # options = [&quot;L1&quot;]
        regularizaiton_weight = 10^-4, # options Real
        loss = &quot;FixedVariance&quot;, # options = [&quot;EstimateVariance&quot;]
        process_weights = [0.5,1.0], # options:  Vector{Real}
        observation_weights = [0.25,0.1], # options: Vector{Real}
        produciton_hyper_parameters = NamedTuple(), # options: Naned tuple with keys (lags=Int,hidden=Int,cell_dim=Int,seed=Int,drop_prob=Real in [0,1],extrap_value=Real,extrap_length=Real)
        prior_q = 0.0, # options: Real
        prior_b = 0.0 # options: Real
        prior_weight = 0.0 # options = Real
        variance_priors = NamedTuple() # named tuple with keys (var_y=Real,sigma_y=Real,rH=Real,sigma_rH=Real,rB=Real,sigma_rB=Real,rF=Real,sigma_rF=Real)
    )</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/Jack-H-Buckner/SciMLFisheries.jl/blob/56c408108bca86edec69314d248b6718fb9b977c/src/StockAssessments.jl#L68-L102">source</a></section></article><h2 id="Production-models"><a class="docs-heading-anchor" href="#Production-models">Production models</a><a id="Production-models-1"></a><a class="docs-heading-anchor-permalink" href="#Production-models" title="Permalink"></a></h2><p>The core of the surplus production model is a function that estimates the growth rate of the population in each time step <span>$r_t$</span>. SciMLFisheries had six choices in production models that fall into one of three primary categories: time delay embedding models, recurrent neural networks, and feed-forward neural networks.  </p><h3 id="Time-Delay-Embedding"><a class="docs-heading-anchor" href="#Time-Delay-Embedding">Time Delay Embedding</a><a id="Time-Delay-Embedding-1"></a><a class="docs-heading-anchor-permalink" href="#Time-Delay-Embedding" title="Permalink"></a></h3><p>Time delay embedding models estimate the growth rate at time <span>$t$</span>  time step as a function of the current biomass <span>$B_t$</span> and prior observations of the biomass and fishing mortality up to time <span>$t-\tau$</span> where <span>$tau$</span> is the &quot;embedding&quot; dimension, a use specified parameter that determines how much of the population’s history is included in the model.</p><p>The simplest model uses a neural network parameterized with weight <span>$w$</span> and biases <span>$b$</span> to approximate a function that maps from the prior observations to the population growth rate.</p><p class="math-container">\[r_t = NN(B_t,\{B_{t-i}\}_{i=1}^{\tau}, \{H_{t-i}\}_{i=1}^{\tau};w,b).\]</p><p>We can build a delay embedding model using the SurplusProduction function by specifying &quot;DelayEmbedding&quot; as the     <code>production_model</code> argument. The Delay embedding model had five hyperparameters that can be tuned to optimize the model&#39;s performance. In this example, all five parameters are listed in the NamedTuple <code>produciton_hyper_parameters</code> and set to their default values. The embedding dimension <span>$\tau$</span> is set equal to <code>lags</code> and must take an integer value. The next argument, <code>hidden,</code> influences how complex (degree of nonlinearity) the production function can be by controlling the number of hidden units in the neural network. The argument <code>seed</code> initializes the random number generator used to sample the initial neural network parameters, and the parameters <code>extrap_value</code> and <code>extrap_length</code> determine the behavior of the model predictions when extrapolating outside of the observed data set. The predicted growth rate will revert to <code>extrap_value</code> in the limit as the abundance of the stock becomes small, and it will revert to <code>-1*extra_value</code> in the limit as the stock becomes large. <code>extrap_length</code> determines how quickly the model reverts to this default behavior outside the range of historical observations. When forecasting, the production model is determined by the fitted neural network <span>$F(B,...)$</span> and the extrapolation parameters</p><p class="math-container">\[r_t =   \left\{
\begin{array}{ll}
      F(B,...) &amp; min(B_t) &lt; B &lt; max(B_t) \\
      \omega(B)F(B,...) + (1-\omega(B)) \rho &amp; B &lt; min(B_t) \\
      \omega(B)F(B,...) - (1-\omega(B)) \rho &amp; B &gt; max(B_t) \\
\end{array} 
\right.  \\
\omega(B) = e^{-\frac{1}{2}\left( \frac{min(min(B_t)-B),B - max(B_t)}{extrap\_length} \right)^2}\]</p><p>where <span>$min(B_t)$</span> is the smallest observation in the data set and <span>$max(B_t)$</span> is the largest. We can also specify the functional form and weight for regularizing the neural network parameters when building the models, using the <code>regualrizaiton_type</code> and <code>regularization_weight</code> arguments. When using the default L2 regularization, the sum of squares penalizes the neural network weights, and L1 uses the sum of absolute values times the <code>regularization_weight.</code></p><pre><code class="language-julia hljs">using UniversalDiffEq
model = SurplusProduction(data,
                        production_model = &quot;DelayEmbedding&quot;, # options Int
                        produciton_hyper_parameters = (lags=5,hidden=10,seed=123,extrap_value=0.0,extrap_length=0.5),
                        regularizaiton_type = &quot;L2&quot;, # options [&quot;L2&quot;, &quot;L1&quot;]
                        regularizaiton_weight = 10^-4 # options Real {x | x &gt;= 0}
                        )</code></pre><p>Overfitting and variable selection are common issues for delay embedding models. We may wish to account for many possible time lags and allow for nonlinear functional forms in the model, but these model features also add many degrees of freedom that allow the model to identify patterns in the training data that do not generalize. This limitation can be addressed by controlling the complexity of the neural network in the standard delay embedding model through the choice of regularization parameters, the number of lags included in the model, and the number of hidden units in the neural network. However, we also developed alternative model structures that take additional approaches to solving the overfitting problem. The approach adds a dropout layer to the neural network. Drop-out layers randomly switch some of the neural network weights to zero during the training process; the model is prevented from learning overly complex functions that depend on the interaction between network parameters, reducing overfitting. To build a model that includes a drop-out layer, choose <code>&quot;DelayEmbeddingDropOut&quot;</code> as the model production model. The dropout model has all the same hyperparameters as the standard delay embedding model, plus an additional parameter <code>drop_prob</code> that defines the probability network weights are set to zero during the training process. The following cell builds a model with a drop-out layer setting all hyperparameters to their default values, <code>drop_prob</code> is included as a keyword argument to show how it can be modified.</p><pre><code class="language-julia hljs">using UniversalDiffEq
model = SurplusProduction(data,
                        production_model = &quot;DelayEmbeddingDropOut&quot;, # options Int
                        produciton_hyper_parameters = (drop_prob=0.1))</code></pre><p>Regularization and dropout can control the degree of nonlinearity incorporated in the model, but they do not directly control the number of inputs. To handle this challenge, we developed a regularization method that attempts to detect the relevant model inputs automatically and sets the effect of all other inputs to zero. This is done by multipying the neural network inputs <span>$X_t = {B_t, B_{t-1}, ..., F_{t-1}, F_{t-2}, ...}$</span> by a vector <span>$I_r$</span>, before the are fed into the neural network. This produces a model of the form</p><p class="math-container">\[   r_t = NN(I_r \circ X_t; w, b)\]</p><p>On its own, this model structure does not reduce overfitting, but it allows us to directly regularize the network inputs. Specifically, we use L1 regularization on the input vector <span>$I_r$</span> and L2 regularization on the neural network weights. L1 regularization will force parameters to equal zero if they are not contributing adequately to the model performance; this allows the model to detect and remove irrelevant variables automatically. Applying L2 regularization to the network weights controls the degree of non-linearity of the fitted model. This regularization scheme can independently address the two primary degrees of freedom that lead to overfitting, variable selection, and nonlinearity. To construct a model of the form, use <code>&quot;DelayEmbeddingARD&quot;</code> as the process model. All keyword arguments are the same as the standard Delay embedding model, except it is possible to specify differnt weights for the L1 and L2 regularization steps by passing a named tuple to the <code>regularizaiton_weight</code> argument. If only a single value is supplied it will be applied to both L1 and L2 staged</p><pre><code class="language-julia hljs">using UniversalDiffEq
model = SurplusProduction(data,
                        production_model = &quot;DelayEmbeddingDropOut&quot;, # options Int
                        regularizaiton_weight = (L1 = 10^-3.5, L2 = 10^-3.5))</code></pre><h3 id="Recurrent-nerual-networks"><a class="docs-heading-anchor" href="#Recurrent-nerual-networks">Recurrent nerual networks</a><a id="Recurrent-nerual-networks-1"></a><a class="docs-heading-anchor-permalink" href="#Recurrent-nerual-networks" title="Permalink"></a></h3><h3 id="Feed-Forward-Networks"><a class="docs-heading-anchor" href="#Feed-Forward-Networks">Feed Forward Networks</a><a id="Feed-Forward-Networks-1"></a><a class="docs-heading-anchor-permalink" href="#Feed-Forward-Networks" title="Permalink"></a></h3><h2 id="Observation-models"><a class="docs-heading-anchor" href="#Observation-models">Observation models</a><a id="Observation-models-1"></a><a class="docs-heading-anchor-permalink" href="#Observation-models" title="Permalink"></a></h2><h3 id="Discrete-approximation"><a class="docs-heading-anchor" href="#Discrete-approximation">Discrete approximation</a><a id="Discrete-approximation-1"></a><a class="docs-heading-anchor-permalink" href="#Discrete-approximation" title="Permalink"></a></h3><h3 id="Linear-approximation"><a class="docs-heading-anchor" href="#Linear-approximation">Linear approximation</a><a id="Linear-approximation-1"></a><a class="docs-heading-anchor-permalink" href="#Linear-approximation" title="Permalink"></a></h3><h2 id="Uncertianty-quantification"><a class="docs-heading-anchor" href="#Uncertianty-quantification">Uncertianty quantification</a><a id="Uncertianty-quantification-1"></a><a class="docs-heading-anchor-permalink" href="#Uncertianty-quantification" title="Permalink"></a></h2><h3 id="Process-errors"><a class="docs-heading-anchor" href="#Process-errors">Process errors</a><a id="Process-errors-1"></a><a class="docs-heading-anchor-permalink" href="#Process-errors" title="Permalink"></a></h3><h3 id="Observation-errors"><a class="docs-heading-anchor" href="#Observation-errors">Observation errors</a><a id="Observation-errors-1"></a><a class="docs-heading-anchor-permalink" href="#Observation-errors" title="Permalink"></a></h3><h3 id="Priors"><a class="docs-heading-anchor" href="#Priors">Priors</a><a id="Priors-1"></a><a class="docs-heading-anchor-permalink" href="#Priors" title="Permalink"></a></h3></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../">« SciMlFisheries</a><a class="docs-footer-nextpage" href="../Modeltesting/">Testing model performance »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.3.0 on <span class="colophon-date" title="Tuesday 26 March 2024 14:22">Tuesday 26 March 2024</span>. Using Julia version 1.7.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
